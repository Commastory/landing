
# ğŸ§  emma AI Stack PoC Template

This template deploys a complete LLM-ready environment in your own cloud using **emma**.  
It includes:

- **Ollama** â€” lightweight LLM backend with GPU support
- **Qdrant** â€” high-performance vector database
- **Streamlit UI** â€” simple demo interface
- **Kubernetes Autoscaler** â€” for CPU-based scaling

---

## ğŸš€ Quick Start

```bash
# 1. Install emma CLI
curl -sL https://emma.ms/install.sh | bash

# 2. Deploy the full stack
emma apply -f https://github.com/emma-platform/emma-poc-ai-template
```

---

## ğŸ“¦ Stack Overview

| Component   | Image               | Purpose                        |
|------------|---------------------|--------------------------------|
| Ollama     | `ollama/ollama`     | LLM API (e.g., llama2)         |
| Qdrant     | `qdrant/qdrant`     | Vector DB for embeddings       |
| UI         | `streamlit/streamlit` | Web interface for queries      |
| Autoscaler | HPA                 | Auto scale `ollama-api` pods   |

---

## ğŸ” Endpoints

- `http://<your-domain>:11434` â€” Ollama API
- `http://<your-domain>:6333` â€” Vector DB (REST)
- `http://<your-domain>:8501` â€” Streamlit UI

---

## ğŸ“… Need help?

Book a 1:1 walkthrough â†’ [emma.ms](https://emma.ms)

